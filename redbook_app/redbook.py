import requests
import json
import re
import pandas as pd
import os
from datetime import datetime
import time
import random

# ä»ç¯å¢ƒå˜é‡è·å– Cookie
def get_cookies():
    # cookies_str = os.environ.get('XIAOHONGSHU_COOKIES')
    # if cookies_str:
    #     try:
    #         return json.loads(cookies_str)
    #     except:
    #         # å¦‚æœ JSON è§£æå¤±è´¥ï¼Œå°è¯•è§£æä¸ºå­—å…¸
    #         cookies = {}
    #         for item in cookies_str.split(';'):
    #             if '=' in item:
    #                 key, value = item.strip().split('=', 1)
    #                 cookies[key] = value
    #         return cookies
    
    # å¦‚æœç¯å¢ƒå˜é‡ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤ Cookie
    return {
    "a1": "19363212f4acl9fm3846czee2men7mekzmbtw3zgg30000352410",
    "webId": "03a0d588d937b6c7f6f8a607e08e2415",
    "gid": "yjqKqJy42fuiyjqKqJyJi6qu40S1ji6qY4KSDkkuddJ6d9q8IW6dTE888q2J4y88fYq0dWKq",
    "customerClientId": "195177604463666",
    "abRequestId": "03a0d588d937b6c7f6f8a607e08e2415",
    "x-user-id-creator.xiaohongshu.com": "5aae83144eacab32f473510e",
    "web_session": "040069b06170eb56e33d3d33bc3a4b976c002b",
    "unread": "{%22ub%22:%226889bc8f0000000025020287%22%2C%22ue%22:%226888b4f7000000000403e017%22%2C%22uc%22:25}",
    "webBuild": "4.75.0",
    "xsecappid": "ratlin",
    "customer-sso-sid": "68c517533119020201092856bbpbirxkwiaal1rh",
    "x-user-id-pgy.xiaohongshu.com": "67b6cf6804ee000000000001",
    "solar.beaker.session.id": "AT-68c517533119024497680616pivku1fb8fbggqox",
    "access-token-pgy.xiaohongshu.com": "customer.pgy.AT-68c517533119024497680616pivku1fb8fbggqox",
    "access-token-pgy.beta.xiaohongshu.com": "customer.pgy.AT-68c517533119024497680616pivku1fb8fbggqox",
    "acw_tc": "0a422b2617540157344662525e944ed9e4cee10a5dd91bd39d099502a703e5",
    "loadts": "1754015735894",
    "websectiga": "cffd9dcea65962b05ab048ac76962acee933d26157113bb213105a116241fa6c",
    "sec_poison_id": "9c7b8686-a616-49e1-b6e4-e28efae4545"
}

# åˆå§‹åŒ–å…¨å±€cookieså˜é‡ï¼Œå…è®¸åŠ¨æ€æ›´æ–°
cookies = get_cookies()

def scrape_xiaohongshu_blogger(user_id):
    # åŸºç¡€URL
    user_info_url = f"https://pgy.xiaohongshu.com/api/solar/cooperator/user/blogger/{user_id}"
    data_summary_url = f"https://pgy.xiaohongshu.com/api/pgy/kol/data/data_summary?userId={user_id}&business=1"
    
    # ç”Ÿæˆæ—¶é—´æˆ³
    import time
    current_timestamp = str(int(time.time() * 1000))
    
    # ä¸¤ä¸ªè¯·æ±‚å…±ç”¨çš„è¯·æ±‚å¤´
    headers = {
        'accept': 'application/json, text/plain, */*',
        'accept-language': 'zh-CN,zh;q=0.9',
        'cache-control': 'no-cache',
        'pragma': 'no-cache',
        'priority': 'u=1, i',
        'referer': f'https://pgy.xiaohongshu.com/solar/pre-trade/blogger-detail/{user_id}',
        'sec-ch-ua': '"Not)A;Brand";v="8", "Chromium";v="138", "Google Chrome";v="138"',
        'sec-ch-ua-mobile': '?0',
        'sec-ch-ua-platform': '"macOS"',
        'sec-fetch-dest': 'empty',
        'sec-fetch-mode': 'cors',
        'sec-fetch-site': 'same-origin',
        'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36',
        'x-b3-traceid': f'{random.randint(100000000000000, 999999999999999):x}',
        'x-s': 'O6slsjMlsBsK1BFWZgvlOlsWOjFL1lAbOBTp0jMGZgs3',
        'x-s-common': '2UQAPsHCPUIjqArjwjHjNsQhPsHCH0rjNsQhPaHCH0c1PahFHjIj2eHjwjQ+GnPW/MPjNsQhPUHCHdQY4BlkJjMAyBpVJsHVHdWFH0ijPshIN0D7PaHVHdWMH0ijP/DA+0PUP/Qf+Bb0JeSfJ/Ph+e802fpSPfMSJ04T8nTCJnQF4A+C89qAPeZIPePMP0clPsHVHdW9H0ijHjIj2eqjwjHjNsQhwsHCHDDAwoQH8B4AyfRI8FS98g+Dpd4daLP3JFSb/BMsn0pSPM87nrldzSzQ2bPAGdb7zgQB8nph8emSy9E0cgk+zSS1qgzianYt8Lzf/LzN4gzaa/+NqMS6qS4HLozoqfQnPbZEp98QyaRSp9P98pSl4oSzcgmca/P78nTTL08z/sVManD9q9z18np/8db8aob7JeQl4epsPrzsagW3tF4ryaRApdz3agYDq7YM47HFqgzkanYMGLSbP9LA/bGIa/+nprSe+9LI4gzVPDbrJg+P4fprLFTALMm7+LSb4d+kpdzt/7b7wrQM498cqBzSpr8g/FSh+bzQygL9nSm7qSmM4epQ4flY/BQdqA+l4oYQ2BpAPp87arS34nMQyFSE8nkdqMD6pMzd8/4SL7bF8aRr+7+rG7mkqBpD8pSUzozQcA8Szb87PDSb/d+/qgzVJfl/4LExpdzQ4fRSy7bFP9+y+7+nJAzdaLp/2LSiz/QH+FlpagYTLrRCJnRQyn+G8pm7zDS9ypHUcfRAzoi7q7Yn4BzQ408S8eq78pSx4gzQznzS+S4j80QM49kQyrkAP9RSqA8r4fpLLozwGML98LzM4ApQ4SSIG9pS8n8n47pIwn4AL7b7JFDALDlQ2BMVq7bFq9bc47SAqFYjaFc7q9zs8o+34gzSanS68nc6cnLAG9l+aLpO8nzj4d+nJFpaanTS8pzn4rMQyFzD4op7qrRl4F+QPFkSpopFzDS3P7+kqgzfanDA8p4c4F8tqg4PwopFaDSeyApQcAz1LB8CpDkCP9Ll4g4ianYizFS3PBpD4g46nSk34rQp+g+gcpbranTo/rkl4rTYqg4Mag8D8/8n4oYzqrTSPFSm8/bP2dQQzLkAyFQO8nkn4ApcLoz9anSdqAbM4eQQcAmApFz8pFS3J7+h2fzAPMm7/rSi8nLIpdzYcf+g+LShJrSQy/pSn/mtqAmy/7+kG94Sygb7JDSbpobQcFcM/ob7arSh/opQPAmSpAZFLB4B/9pk4gq9agYczL4M4F4jJApS2rb9q7Yn4bLhpdcEanTlarSeqBlwqgzf8gb7yrShJ7+n8n4SpMm72ezc4BlQcFFItM8FJDSkaBlF2Skba/PMqM8jP7+3qf4Sngp7L9Ql4BlQ2rY9anT6q98l4BMQ40pS2BchGFSbnnSHJ/WhaL+8qDSe4fp3Loql2SmFPSml4eSQ2rzyanW7qMzS/9pn4gqEqrzcJDSi/bYCpdz8/MmF8DSkLeQQynThagY/qDS9N9prw/pAL9EV8LQn4F+Qyr8CzM87cpbM4AQQcURSp04rnrSkLrG6JFbS8S8Fpbmc4ob6GFlsJn4npFSkJbSILo4wanT9qA80wBEQy/YiJ7b7pFS32DlH4gzgJMmFtFSi4p+Q4DMfanYCLoQn49zQygQPaLLMqA+M4MY6G9MmanYi8LSe+g+8cDTAyM878DSenLQQzLlbGnlQnLS9/pP6JBY+agGAqAmU+9pgpd4FaLL6qMSc4BbQzgQ1aL+mq9zM4FkQ4fMYcdb7nrSe+gPAG9WFaS8FcLRl4oQQ4fzSpMmFLrSiPo+//giManYdq98s8o+xpdzVqMStqA8l4AYUq0mApSmFqDDAJ7+/qURSzb8FzLS9/BMQ2b+xLop7zpbCLdmQ2e+SPpm7Gd+YPBphJBlGqM8FGFDAG0zQyFEALMSa4rS38g+DqgzNHjIj2eDjwjFl+/Pl+ec7+eWhNsQhP/Zjw0ZVHdWlPaHCHflk4BLjKc==',
        'x-t': current_timestamp,
    }
    
    # å‘é€ç¬¬ä¸€ä¸ªè¯·æ±‚è·å–ç”¨æˆ·ä¿¡æ¯
    try:
        response1 = requests.get(user_info_url, headers=headers, cookies=cookies)
        response1.raise_for_status()
        user_data = response1.json()
        
        # å‘é€ç¬¬äºŒä¸ªè¯·æ±‚è·å–æ•°æ®æ‘˜è¦
        response2 = requests.get(data_summary_url, headers=headers, cookies=cookies)
        response2.raise_for_status()
        summary_data = response2.json()
        
        # æå–æ‰€éœ€ä¿¡æ¯
        result = {
            "è¾¾äººåç§°": user_data.get("data", {}).get("name", "æœªçŸ¥"),
            "id": user_data.get("data", {}).get("redId", "æœªçŸ¥"),
            "ä¸»é¡µé“¾æ¥": f"https://www.xiaohongshu.com/user/profile/{user_id}",
            "ç²‰ä¸æ•°(W)": round(user_data.get("data", {}).get("fansCount", 0) / 10000, 1),
        }
        
        # å¤„ç†èµè—æ•°ï¼Œå¯èƒ½æ˜¯æ•´æ•°æˆ–å­—ç¬¦ä¸²
        like_collect = user_data.get("data", {}).get("likeCollectCountInfo", 0)
        if isinstance(like_collect, str):
            # å¦‚æœæ˜¯å­—ç¬¦ä¸²(ä¾‹å¦‚"80.0w"æˆ–"80.0ä¸‡")ï¼Œåˆ™å»æ‰å•ä½å¹¶è½¬æ¢ä¸ºæµ®ç‚¹æ•°
            like_collect = float(like_collect.replace("w", "").replace("ä¸‡", ""))
        elif isinstance(like_collect, (int, float)):
            # å¦‚æœå·²ç»æ˜¯æ•°å­—ï¼Œåˆ™è½¬æ¢ä¸ºä¸‡ä¸ºå•ä½
            like_collect = like_collect / 10000
        
        result["èµè—æ•°(W)"] = round(like_collect, 1)
        result["äº’åŠ¨ä¸­ä½æ•°"] = summary_data.get("data", {}).get("mEngagementNum", "N/A")
        result["é˜…è¯»ä¸­ä½æ•°"] = summary_data.get("data", {}).get("readMedian", "N/A")
        result["æ›å…‰ä¸­ä½æ•°"] = summary_data.get("data", {}).get("mAccumImpNum", "N/A")
        result["å¤–æº¢è¿›åº—ä¸­ä½æ•°"] = summary_data.get("data", {}).get("mCpuvNum", "N/A")
        

        return result
        
    except requests.exceptions.HTTPError as e:
        if e.response.status_code == 406:
            print(f"âŒ 406é”™è¯¯ - è¯·æ±‚ä¸è¢«æ¥å—: {e}")
            print("ğŸ’¡ è§£å†³å»ºè®®:")
            print("   1. Cookieå¯èƒ½å·²è¿‡æœŸï¼Œè¯·æ›´æ–°Cookie")
            print("   2. è¯·æ±‚å¤´å¯èƒ½ä¸å®Œæ•´æˆ–æ ¼å¼é”™è¯¯")
            print("   3. ç”¨æˆ·ä»£ç†å¯èƒ½è¢«æœåŠ¡å™¨æ‹’ç»")
            print("   4. è¯·è®¿é—®åº”ç”¨é¡µé¢ä½¿ç”¨CookieéªŒè¯åŠŸèƒ½")
            return None
        elif e.response.status_code == 401:
            print(f"âŒ 401é”™è¯¯ - æœªæˆæƒè®¿é—®: {e}")
            print("ğŸ’¡ Cookieå·²è¿‡æœŸæˆ–æ— æ•ˆï¼Œè¯·é‡æ–°è·å–Cookie")
            return None
        elif e.response.status_code == 403:
            print(f"âŒ 403é”™è¯¯ - è®¿é—®è¢«ç¦æ­¢: {e}")
            print("ğŸ’¡ å¯èƒ½è§¦å‘äº†åçˆ¬è™«æœºåˆ¶ï¼Œå»ºè®®ç¨åå†è¯•æˆ–æ›´æ–°Cookie")
            return None
        else:
            print(f"âŒ HTTPé”™è¯¯ {e.response.status_code}: {e}")
            return None
    except requests.exceptions.RequestException as e:
        print(f"âŒ ç½‘ç»œè¯·æ±‚å‡ºé”™: {e}")
        return None
    except json.JSONDecodeError:
        print("âŒ è§£æJSONå“åº”å‡ºé”™ - æœåŠ¡å™¨è¿”å›çš„ä¸æ˜¯æœ‰æ•ˆJSONæ ¼å¼")
        return None
    except Exception as e:
        print(f"å‘ç”Ÿé”™è¯¯: {e}")
        return None

def extract_user_id_from_url(url):
    """ä» URL ä¸­æå–ç”¨æˆ· ID"""
    # æ”¯æŒå¤šç§ URL æ ¼å¼
    patterns = [
        r'blogger-detail/([a-zA-Z0-9]+)',  # åŸå§‹æ ¼å¼
        r'user/profile/([a-zA-Z0-9]+)',    # ç”¨æˆ·ä¸»é¡µæ ¼å¼
        r'xiaohongshu\.com/user/profile/([a-zA-Z0-9]+)',  # å®Œæ•´ç”¨æˆ·ä¸»é¡µ URL
        r'xiaohongshu\.com/discovery/item/([a-zA-Z0-9]+)'  # ç¬”è®° URL
    ]
    
    for pattern in patterns:
        match = re.search(pattern, url)
        if match:
            return match.group(1)
    
    return None

def process_urls(urls):
    """å¤„ç†å¤šä¸ªURLå¹¶è¿”å›ç»“æœåˆ—è¡¨"""
    all_data = []
    results = []
    
    print(f"ğŸ” process_urls è°ƒè¯•ä¿¡æ¯:")
    print(f"  è¾“å…¥URLæ•°é‡: {len(urls)}")
    print(f"  å‰3ä¸ªURL: {urls[:3]}")
    
    # å°†å¤šä¸ªURLåˆ†æ‰¹å¤„ç†
    batch_size = 5  # æ¯æ‰¹å¤„ç†5ä¸ªURL
    
    for i, url in enumerate(urls):
        url = url.strip()
        if not url:
            continue
            
        # ä»URLä¸­æå–ç”¨æˆ·ID
        user_id = extract_user_id_from_url(url)
        
        if user_id:
            log_message = f"æ­£åœ¨å¤„ç†URL {i+1}/{len(urls)}: {url}, ç”¨æˆ·ID: {user_id}"
            results.append({"status": "processing", "message": log_message})
            
            try:
                # ä½¿ç”¨æ›´åˆç†çš„éšæœºå»¶æ—¶
                delay = random.uniform(2, 5)  # 2-5ç§’çš„éšæœºå»¶æ—¶
                results.append({"status": "info", "message": f"ç­‰å¾… {delay:.1f} ç§’..."})
                time.sleep(delay)
                
                # çˆ¬å–åšä¸»æ•°æ®
                result = scrape_xiaohongshu_blogger(user_id)
                
                if result:
                    all_data.append(result)
                    print(f"âœ… æˆåŠŸçˆ¬å–ç”¨æˆ· {user_id}: {result.get('è¾¾äººåç§°', 'æœªçŸ¥')}")
                    results.append({"status": "success", "message": f"æˆåŠŸè·å– {result['è¾¾äººåç§°']} çš„æ•°æ®"})
                else:
                    print(f"âŒ çˆ¬å–ç”¨æˆ· {user_id} å¤±è´¥")
                    results.append({"status": "error", "message": f"è·å–ç”¨æˆ· {user_id} æ•°æ®å¤±è´¥"})
            except Exception as e:
                results.append({"status": "error", "message": f"å¤„ç†ç”¨æˆ· {user_id} æ—¶å‡ºé”™: {str(e)}"})
            
            # æ¯å¤„ç†ä¸€æ‰¹URLï¼Œé¢å¤–ä¼‘æ¯è¾ƒçŸ­æ—¶é—´
            if (i + 1) % batch_size == 0 and i < len(urls) - 1:
                pause_time = random.uniform(5, 10)  # 5-10ç§’çš„ä¼‘æ¯æ—¶é—´
                results.append({"status": "info", "message": f"æ‰¹é‡å¤„ç†æš‚åœï¼Œä¼‘æ¯ {pause_time:.1f} ç§’..."})
                time.sleep(pause_time)
        else:
            results.append({"status": "error", "message": f"æ— æ³•ä»URLä¸­æå–ç”¨æˆ·ID: {url}"})
    
    print(f"ğŸ“Š process_urls å®Œæˆç»Ÿè®¡:")
    print(f"  æˆåŠŸçˆ¬å–æ•°æ®æ¡æ•°: {len(all_data)}")
    print(f"  è¿”å›ç»“æœæ¡æ•°: {len(results)}")
    if all_data:
        print(f"  æ•°æ®é¢„è§ˆ: {all_data[:2]}")
    
    return all_data, results

def save_to_excel(data_list):
    """ä¿å­˜æ•°æ®åˆ°Excelå¹¶è¿”å›æ–‡ä»¶è·¯å¾„"""
    if not data_list:
        print("âŒ æ²¡æœ‰æ•°æ®å¯ä¿å­˜")
        return None
        
    print(f"ğŸ“Š å‡†å¤‡ä¿å­˜ {len(data_list)} æ¡æ•°æ®åˆ°Excel")
    
    # æ·»åŠ æ—¶é—´æˆ³åˆ°æ–‡ä»¶å
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"å°çº¢ä¹¦è¾¾äººæ•°æ®_{timestamp}.xlsx"
    
    # å°è¯•å¤šä¸ªä¿å­˜è·¯å¾„ï¼ˆé€‚é…äº‘å¹³å°ï¼‰
    save_paths = [
        os.path.join("results", filename),      # resultsç›®å½•
        filename,                               # å½“å‰ç›®å½•
        os.path.join("/tmp", filename),         # ä¸´æ—¶ç›®å½•ï¼ˆäº‘å¹³å°ï¼‰
        os.path.join(os.getcwd(), filename),    # æ˜ç¡®çš„å½“å‰å·¥ä½œç›®å½•
        os.path.join("/app", filename),         # åº”ç”¨æ ¹ç›®å½•
        os.path.join(os.path.expanduser("~"), filename)  # ç”¨æˆ·ç›®å½•
    ]
    
    # åˆ›å»ºDataFrame
    try:
        df = pd.DataFrame(data_list)
        print(f"âœ… DataFrameåˆ›å»ºæˆåŠŸï¼Œå½¢çŠ¶: {df.shape}")
        
        # æ‰“å°æ•°æ®é¢„è§ˆ
        print("ğŸ“‹ æ•°æ®é¢„è§ˆ:")
        for i, item in enumerate(data_list[:2]):  # åªæ˜¾ç¤ºå‰2æ¡
            print(f"  {i+1}. {item.get('è¾¾äººåç§°', 'æœªçŸ¥')}: {item.get('ç²‰ä¸æ•°(W)', 'N/A')}Wç²‰ä¸")
            
    except Exception as e:
        print(f"âŒ åˆ›å»ºDataFrameå¤±è´¥: {e}")
        return None
    
    saved_path = None
    save_errors = []
    
    # å°è¯•ä¿å­˜åˆ°ä¸åŒè·¯å¾„
    for i, save_path in enumerate(save_paths):
        try:
            print(f"ğŸ”„ å°è¯•ä¿å­˜è·¯å¾„ {i+1}/{len(save_paths)}: {save_path}")
            
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            directory = os.path.dirname(save_path)
            if directory and not os.path.exists(directory):
                print(f"ğŸ“ åˆ›å»ºç›®å½•: {directory}")
                os.makedirs(directory, exist_ok=True)
            
            # ä¿å­˜åˆ°Excel
            df.to_excel(save_path, index=False, engine='openpyxl')
            print(f"ğŸ’¾ Excelä¿å­˜æ“ä½œå®Œæˆ")
            
            # éªŒè¯æ–‡ä»¶æ˜¯å¦æˆåŠŸåˆ›å»º
            if os.path.exists(save_path):
                file_size = os.path.getsize(save_path)
                print(f"âœ… æ–‡ä»¶éªŒè¯æˆåŠŸ: {save_path}")
                print(f"ğŸ“ æ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚")
                
                if file_size > 1024:  # è‡³å°‘1KB
                    saved_path = save_path
                    print(f"ğŸ‰ æ–‡ä»¶æˆåŠŸä¿å­˜åˆ°: {save_path}")
                    break
                else:
                    print(f"âš ï¸ æ–‡ä»¶å¤ªå° ({file_size} å­—èŠ‚)ï¼Œå¯èƒ½ä¿å­˜å¤±è´¥")
                    save_errors.append(f"{save_path}: æ–‡ä»¶å¤ªå°")
            else:
                print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {save_path}")
                save_errors.append(f"{save_path}: æ–‡ä»¶ä¸å­˜åœ¨")
                
        except Exception as e:
            error_msg = f"ä¿å­˜åˆ° {save_path} å¤±è´¥: {e}"
            print(f"âŒ {error_msg}")
            save_errors.append(error_msg)
            continue
    
    if saved_path:
        print(f"ğŸ† æœ€ç»ˆæˆåŠŸä¿å­˜: {saved_path}")
        return os.path.basename(saved_path)  # è¿”å›æ–‡ä»¶å
    else:
        print("ğŸ’¥ æ‰€æœ‰ä¿å­˜è·¯å¾„éƒ½å¤±è´¥äº†!")
        print("ğŸ“‹ é”™è¯¯è¯¦æƒ…:")
        for error in save_errors:
            print(f"  - {error}")
        
        # å°è¯•è·å–æ›´å¤šè°ƒè¯•ä¿¡æ¯
        print("ğŸ” ç³»ç»Ÿä¿¡æ¯:")
        print(f"  å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
        print(f"  å¯å†™æ€§æµ‹è¯•...")
        
        for path in ["/tmp", ".", "/app"]:
            try:
                test_file = os.path.join(path, "test_write.tmp")
                with open(test_file, 'w') as f:
                    f.write("test")
                if os.path.exists(test_file):
                    os.remove(test_file)
                    print(f"  âœ… {path} å¯å†™")
                else:
                    print(f"  âŒ {path} å†™å…¥å¤±è´¥")
            except Exception as e:
                print(f"  âŒ {path} ä¸å¯å†™: {e}")
        
        return None