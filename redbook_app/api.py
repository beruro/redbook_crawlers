from fastapi import FastAPI, UploadFile, File, BackgroundTasks, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse, HTMLResponse, StreamingResponse
from pydantic import BaseModel
import os
import sys
from typing import List, Dict, Any, Optional
from fastapi.staticfiles import StaticFiles
import pandas as pd
from datetime import datetime
import threading
import time
import requests
import io

# å°†å½“å‰ç›®å½•æ·»åŠ åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
import redbook

app = FastAPI(title="å°çº¢ä¹¦è¾¾äººæ•°æ®çˆ¬å–å·¥å…· API")

# æ·»åŠ CORSä¸­é—´ä»¶ï¼Œå…è®¸å‰ç«¯è·¨åŸŸè¯·æ±‚
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # åœ¨ç”Ÿäº§ç¯å¢ƒä¸­åº”è¯¥é™åˆ¶ä¸ºç‰¹å®šåŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# åˆ›å»ºç”¨äºå­˜å‚¨ç»“æœçš„ç›®å½•
os.makedirs("results", exist_ok=True)

class ProcessStatus(BaseModel):
    status: str
    message: str
    file_path: Optional[str] = None

# å…¨å±€å˜é‡å­˜å‚¨å¤„ç†çŠ¶æ€
processing_status = []
result_file_path = None

# æ·»åŠ å…¨å±€å˜é‡å­˜å‚¨æœ€æ–°çš„æ•°æ®ï¼ˆå†…å­˜æ–¹æ¡ˆï¼‰
latest_scraped_data = None
latest_scrape_timestamp = None

# æŒ‚è½½é™æ€æ–‡ä»¶
frontend_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "frontend")
app.mount("/frontend", StaticFiles(directory=frontend_dir), name="frontend")

@app.post("/api/process")
async def process_data(background_tasks: BackgroundTasks, urls: str = Form(...)):
    global processing_status, result_file_path
    
    # é‡ç½®çŠ¶æ€
    processing_status = []
    result_file_path = None
    
    # åˆ†å‰²URLå¹¶è¿‡æ»¤ç©ºè¡Œ
    url_list = [url.strip() for url in urls.strip().split('\n') if url.strip()]
    
    # éªŒè¯URLåˆ—è¡¨
    if not url_list:
        return {"error": "æ²¡æœ‰æä¾›æœ‰æ•ˆçš„URL"}
    
    # æ·»åŠ åˆå§‹çŠ¶æ€ä¿¡æ¯
    processing_status.append({"status": "info", "message": f"å‡†å¤‡å¤„ç† {len(url_list)} ä¸ªURL..."})
    
    # åœ¨åå°ä»»åŠ¡ä¸­å¤„ç†URL
    background_tasks.add_task(process_urls_background, url_list)
    
    # ç«‹å³è¿”å›å“åº”ï¼Œä¸ç­‰å¾…å¤„ç†å®Œæˆ
    return {"message": f"å¤„ç†å·²å¼€å§‹ï¼Œå…± {len(url_list)} ä¸ªURLï¼Œè¯·é€šè¿‡çŠ¶æ€APIæŸ¥è¯¢è¿›åº¦", "url_count": len(url_list)}

# ä¿®æ”¹ process_urls_background å‡½æ•°
async def process_urls_background(url_list):
    global processing_status, result_file_path
    
    try:
        # æ›´æ–°çŠ¶æ€ä¸ºå¼€å§‹å¤„ç†
        processing_status.append({"status": "info", "message": f"å¼€å§‹å¤„ç† {len(url_list)} ä¸ªURL..."})
        
        # å¤„ç† URL
        data_list, results = redbook.process_urls(url_list)
        
        # æ›´æ–°å¤„ç†ç»“æœ
        processing_status.extend(results)
        
        # å¦‚æœæœ‰æ•°æ®ï¼Œä¿å­˜åˆ° Excel
        if data_list:
            # ä¿å­˜åˆ°å…¨å±€å˜é‡ï¼ˆå†…å­˜æ–¹æ¡ˆï¼‰
            global latest_scraped_data, latest_scrape_timestamp
            latest_scraped_data = data_list
            latest_scrape_timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            print(f"ğŸ’¾ å†…å­˜æ•°æ®ä¿å­˜è°ƒè¯•ä¿¡æ¯:")
            print(f"  æ•°æ®æ¡æ•°: {len(data_list)}")
            print(f"  æ—¶é—´æˆ³: {latest_scrape_timestamp}")
            print(f"  æ•°æ®é¢„è§ˆ: {data_list[:2] if len(data_list) > 0 else 'ç©º'}")
            
            try:
                processing_status.append({"status": "info", "message": f"å‡†å¤‡ä¿å­˜ {len(data_list)} æ¡æ•°æ®åˆ°Excel..."})
                
                filename = redbook.save_to_excel(data_list)
                if filename:
                    # save_to_excel ç°åœ¨å·²ç»å¤„ç†äº†æ–‡ä»¶ä¿å­˜å’Œè·¯å¾„ï¼Œä¸éœ€è¦å†ç§»åŠ¨
                    # æŸ¥æ‰¾å®é™…ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
                    possible_paths = [
                        os.path.join("results", filename),
                        filename,
                        os.path.join("/tmp", filename),
                        os.path.join(os.getcwd(), filename),
                        os.path.join("/app", filename),
                        os.path.join(os.path.expanduser("~"), filename)
                    ]
                    
                    actual_path = None
                    for path in possible_paths:
                        if os.path.exists(path):
                            actual_path = path
                            file_size = os.path.getsize(path)
                            print(f"æ‰¾åˆ°æ–‡ä»¶: {path}, å¤§å°: {file_size} å­—èŠ‚")
                            break
                    
                    if actual_path:
                        result_file_path = actual_path
                        processing_status.append({"status": "success", "message": f"âœ… æ•°æ®å·²æˆåŠŸä¿å­˜åˆ° {filename}"})
                        processing_status.append({"status": "info", "message": f"ğŸ“ æ–‡ä»¶ä½ç½®: {actual_path}"})
                        print(f"æ–‡ä»¶å®é™…ä¿å­˜ä½ç½®: {actual_path}")
                    else:
                        # æ–‡ä»¶ä¿å­˜å¤±è´¥ï¼Œä½†æˆ‘ä»¬æœ‰å†…å­˜å¤‡ä»½
                        processing_status.append({"status": "warning", "message": f"âš ï¸ æ–‡ä»¶ä¿å­˜å¤±è´¥ï¼Œä½†æ•°æ®å·²ä¿å­˜åˆ°å†…å­˜"})
                        processing_status.append({"status": "info", "message": "ğŸ“¥ å¯ä»¥ä½¿ç”¨å†…å­˜ä¸‹è½½åŠŸèƒ½"})
                        result_file_path = None
                else:
                    # æ–‡ä»¶ä¿å­˜å®Œå…¨å¤±è´¥ï¼Œä½†æˆ‘ä»¬æœ‰å†…å­˜å¤‡ä»½
                    processing_status.append({"status": "warning", "message": "âš ï¸ æ–‡ä»¶ä¿å­˜å¤±è´¥ï¼Œä½†æ•°æ®å·²ä¿å­˜åˆ°å†…å­˜"})
                    processing_status.append({"status": "info", "message": "ğŸ“¥ å¯ä»¥ä½¿ç”¨å†…å­˜ä¸‹è½½åŠŸèƒ½"})
                    result_file_path = None
            except Exception as e:
                processing_status.append({"status": "error", "message": f"ä¿å­˜Excelæ—¶å‡ºé”™: {str(e)}"})
        else:
            processing_status.append({"status": "warning", "message": "æ²¡æœ‰æ•°æ®å¯ä¿å­˜"})
            
        # æ·»åŠ å¤„ç†å®ŒæˆçŠ¶æ€
        processing_status.append({"status": "success", "message": "æ‰€æœ‰URLå¤„ç†å®Œæˆ"})
        
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        processing_status.append({"status": "error", "message": f"å¤„ç†URLæ—¶å‡ºé”™: {str(e)}"})
        print(f"å¤„ç†URLæ—¶é”™è¯¯è¯¦æƒ…: {error_detail}")

@app.get("/api/status")
async def get_status():
    global processing_status, result_file_path
    
    try:
        # ç¡®ä¿processing_statusæ˜¯ä¸€ä¸ªåˆ—è¡¨
        if not isinstance(processing_status, list):
            processing_status = []
        
        # ç¡®ä¿result_file_pathæ˜¯å­—ç¬¦ä¸²æˆ–None
        file_path = result_file_path if isinstance(result_file_path, str) else None
        
        # æ„å»ºå“åº”æ•°æ®
        response_data = {
            "status": processing_status,
            "file_path": file_path,
            "timestamp": datetime.now().isoformat()
        }
        
        # éªŒè¯å“åº”æ•°æ®å¯ä»¥åºåˆ—åŒ–ä¸ºJSON
        import json
        json.dumps(response_data, ensure_ascii=False)
        
        return response_data
        
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"è·å–çŠ¶æ€æ—¶é”™è¯¯è¯¦æƒ…: {error_detail}")
        
        # å³ä½¿å‡ºé”™ï¼Œä¹Ÿè¿”å›ä¸€ä¸ªæœ‰æ•ˆçš„JSONå“åº”
        emergency_response = {
            "status": [
                {"status": "error", "message": f"è·å–çŠ¶æ€å‡ºé”™: {str(e)}"},
                {"status": "info", "message": "å¦‚æœæ•°æ®å¤„ç†å·²å®Œæˆï¼Œè¯·å°è¯•ä¸‹è½½ç»“æœ"}
            ],
            "file_path": result_file_path if isinstance(result_file_path, str) else None,
            "error_detail": str(e),
            "timestamp": datetime.now().isoformat()
        }
        
        return emergency_response

@app.get("/api/download")
async def download_file():
    global result_file_path
    
    # å®šä¹‰å¯èƒ½çš„æ–‡ä»¶æŸ¥æ‰¾è·¯å¾„
    search_paths = [
        "results",           # resultsç›®å½•
        ".",                # å½“å‰ç›®å½•
        "/tmp",             # ä¸´æ—¶ç›®å½•ï¼ˆäº‘å¹³å°å¸¸ç”¨ï¼‰
        os.getcwd(),        # å½“å‰å·¥ä½œç›®å½•
        os.path.dirname(os.path.abspath(__file__))  # è„šæœ¬æ‰€åœ¨ç›®å½•
    ]
    
    found_files = []
    
    # 1. é¦–å…ˆæ£€æŸ¥å…¨å±€å˜é‡ä¸­çš„æ–‡ä»¶è·¯å¾„
    if result_file_path:
        if os.path.exists(result_file_path):
            return FileResponse(
                path=result_file_path,
                filename=os.path.basename(result_file_path),
                media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
        else:
            print(f"å…¨å±€è·¯å¾„æ–‡ä»¶ä¸å­˜åœ¨: {result_file_path}")
    
    # 2. åœ¨æ‰€æœ‰å¯èƒ½çš„è·¯å¾„ä¸­æŸ¥æ‰¾Excelæ–‡ä»¶
    for search_path in search_paths:
        try:
            if os.path.exists(search_path) and os.path.isdir(search_path):
                excel_files = []
                for file in os.listdir(search_path):
                    if file.endswith('.xlsx') and 'å°çº¢ä¹¦è¾¾äººæ•°æ®' in file:
                        full_path = os.path.join(search_path, file)
                        if os.path.isfile(full_path):
                            excel_files.append(full_path)
                
                found_files.extend(excel_files)
                print(f"åœ¨ {search_path} ä¸­æ‰¾åˆ° {len(excel_files)} ä¸ªExcelæ–‡ä»¶")
                
        except Exception as e:
            print(f"æœç´¢è·¯å¾„ {search_path} æ—¶å‡ºé”™: {e}")
            continue
    
    # 3. å¦‚æœæ‰¾åˆ°æ–‡ä»¶ï¼Œé€‰æ‹©æœ€æ–°çš„
    if found_files:
        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œé€‰æ‹©æœ€æ–°çš„
        try:
            latest_file = max(found_files, key=lambda x: os.path.getmtime(x))
            print(f"é€‰æ‹©æœ€æ–°æ–‡ä»¶: {latest_file}")
            
            # æ›´æ–°å…¨å±€å˜é‡
            result_file_path = latest_file
            
            return FileResponse(
                path=latest_file,
                filename=os.path.basename(latest_file),
                media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
        except Exception as e:
            print(f"å¤„ç†æ‰¾åˆ°çš„æ–‡ä»¶æ—¶å‡ºé”™: {e}")
    
    # 4. å¦‚æœè¿˜æ˜¯æ²¡æ‰¾åˆ°ï¼Œå°è¯•æŸ¥æ‰¾ä»»ä½•Excelæ–‡ä»¶
    try:
        for search_path in search_paths:
            if os.path.exists(search_path) and os.path.isdir(search_path):
                all_excel = [f for f in os.listdir(search_path) if f.endswith('.xlsx')]
                if all_excel:
                    latest_excel = max([os.path.join(search_path, f) for f in all_excel], 
                                     key=lambda x: os.path.getmtime(x))
                    print(f"æ‰¾åˆ°å¤‡é€‰Excelæ–‡ä»¶: {latest_excel}")
                    return FileResponse(
                        path=latest_excel,
                        filename=os.path.basename(latest_excel),
                        media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
    except Exception as e:
        print(f"æŸ¥æ‰¾å¤‡é€‰æ–‡ä»¶æ—¶å‡ºé”™: {e}")
    
    # 5. å®åœ¨æ‰¾ä¸åˆ°ï¼Œè¿”å›è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯
    debug_info = {
        "error": "æ–‡ä»¶ä¸å­˜åœ¨", 
        "message": "è¯·ç¡®ä¿æ•°æ®å¤„ç†å·²å®Œæˆ",
        "debug": {
            "result_file_path": result_file_path,
            "current_directory": os.getcwd(),
            "searched_paths": search_paths,
            "found_files_count": len(found_files),
            "found_files": found_files[:3] if found_files else [],  # åªæ˜¾ç¤ºå‰3ä¸ªé¿å…å“åº”è¿‡å¤§
        }
    }
    
    return debug_info

@app.post("/api/upload")
async def upload_file(background_tasks: BackgroundTasks, file: UploadFile = File(...)):
    global processing_status, result_file_path
    
    # é‡ç½®çŠ¶æ€
    processing_status = []
    result_file_path = None
    
    # éªŒè¯æ–‡ä»¶ç±»å‹
    if not file.filename.endswith('.txt'):
        return {"error": "è¯·ä¸Šä¼  TXT æ–‡æœ¬æ–‡ä»¶"}
    
    # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
    file_path = f"uploaded_{file.filename}"
    try:
        # ä¿å­˜æ–‡ä»¶
        with open(file_path, "wb") as f:
            f.write(await file.read())
        
        # è¯»å–æ–‡ä»¶å†…å®¹
        url_list = []
        with open(file_path, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if line:  # è·³è¿‡ç©ºè¡Œ
                    url_list.append(line)
        
        # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
        os.remove(file_path)
        
        if not url_list:
            return {"error": "æ–‡ä»¶ä¸­æ²¡æœ‰æœ‰æ•ˆçš„ URL"}
        
        # åœ¨åå°ä»»åŠ¡ä¸­å¤„ç† URL
        processing_status.append({"status": "info", "message": f"ä»æ–‡ä»¶ä¸­è¯»å–äº† {len(url_list)} ä¸ª URL"})
        background_tasks.add_task(process_urls_background, url_list)
        
        return {"message": "æ–‡ä»¶å·²ä¸Šä¼ å¹¶å¼€å§‹å¤„ç†ï¼Œè¯·æŸ¥çœ‹çŠ¶æ€"}
    
    except Exception as e:
        # ç¡®ä¿ä¸´æ—¶æ–‡ä»¶è¢«åˆ é™¤
        if os.path.exists(file_path):
            os.remove(file_path)
        return {"error": f"å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}"}

@app.post("/api/upload-excel")
async def upload_excel_file(background_tasks: BackgroundTasks, file: UploadFile = File(...), column: str = Form("A")):
    global processing_status, result_file_path
    
    # é‡ç½®çŠ¶æ€
    processing_status = []
    result_file_path = None
    
    # éªŒè¯æ–‡ä»¶ç±»å‹
    if not file.filename.endswith(('.xlsx', '.xls')):
        return {"error": "è¯·ä¸Šä¼  Excel æ–‡ä»¶ (.xlsx æˆ– .xls)"}
    
    # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
    file_path = f"uploaded_{file.filename}"
    try:
        # ä¿å­˜æ–‡ä»¶
        with open(file_path, "wb") as f:
            f.write(await file.read())
        
        # è¯»å– Excel æ–‡ä»¶
        try:
            # æ·»åŠ è¯¦ç»†æ—¥å¿—
            processing_status.append({"status": "info", "message": f"æ­£åœ¨è¯»å– Excel æ–‡ä»¶: {file.filename}"})
            
            # å°è¯•è¯»å– Excel æ–‡ä»¶ï¼Œä¸è·³è¿‡ä»»ä½•è¡Œ
            df = pd.read_excel(file_path)
            
            # è®°å½•æ€»è¡Œæ•°
            total_rows = len(df)
            processing_status.append({"status": "info", "message": f"Excel æ–‡ä»¶å…±æœ‰ {total_rows} è¡Œæ•°æ®"})
            
            # æ£€æŸ¥åˆ—æ˜¯å¦å­˜åœ¨
            if column.upper() in df.columns:
                # ä½¿ç”¨åˆ—å
                url_column = column.upper()
                processing_status.append({"status": "info", "message": f"ä½¿ç”¨åˆ—å: {url_column}"})
            elif column.isalpha():
                # å°†åˆ—å­—æ¯è½¬æ¢ä¸ºç´¢å¼• (A->0, B->1, etc.)
                col_idx = ord(column.upper()) - ord('A')
                if col_idx >= 0 and col_idx < len(df.columns):
                    url_column = df.columns[col_idx]
                    processing_status.append({"status": "info", "message": f"ä½¿ç”¨åˆ— {column} (åˆ—å: {url_column})"})
                else:
                    return {"error": f"åˆ— {column} ä¸å­˜åœ¨ï¼Œæ–‡ä»¶åªæœ‰ {len(df.columns)} åˆ—"}
            else:
                return {"error": "è¯·æä¾›æœ‰æ•ˆçš„åˆ—åæˆ–åˆ—å­—æ¯ (å¦‚ A, B, C...)"}
            
            # æå– URL - æ›´å®½æ¾çš„éªŒè¯
            url_list = []
            skipped_rows = 0
            empty_rows = 0
            
            # éå†æ‰€æœ‰è¡Œï¼Œä¸ä½¿ç”¨ dropna()
            for i, row in df.iterrows():
                if url_column in row and pd.notna(row[url_column]):
                    url = str(row[url_column]).strip()
                    if url:
                        # æ›´å®½æ¾çš„ URL éªŒè¯ï¼Œåªè¦ä¸æ˜¯ç©ºå­—ç¬¦ä¸²å°±æ¥å—
                        url_list.append(url)
                    else:
                        empty_rows += 1
                else:
                    skipped_rows += 1
            
            # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
            os.remove(file_path)
            
            # æ·»åŠ è¯¦ç»†æ—¥å¿—
            processing_status.append({"status": "info", "message": f"æ‰¾åˆ° {len(url_list)} ä¸ª URLï¼Œè·³è¿‡ {skipped_rows} è¡Œç©ºå€¼ï¼Œ{empty_rows} è¡Œç©ºå­—ç¬¦ä¸²"})
            
            if not url_list:
                return {"error": "Excel æ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„ URL"}
            
            # æ˜¾ç¤ºå‰å‡ ä¸ª URL ä½œä¸ºç¤ºä¾‹
            sample_size = min(3, len(url_list))
            samples = url_list[:sample_size]
            processing_status.append({"status": "info", "message": f"URL ç¤ºä¾‹: {', '.join(samples)}"})
            
            # åœ¨åå°ä»»åŠ¡ä¸­å¤„ç† URL
            background_tasks.add_task(process_urls_background, url_list)
            
            return {"message": f"Excel æ–‡ä»¶å·²ä¸Šä¼ å¹¶å¼€å§‹å¤„ç† {len(url_list)} ä¸ª URLï¼Œè¯·æŸ¥çœ‹çŠ¶æ€"}
            
        except Exception as e:
            processing_status.append({"status": "error", "message": f"è¯»å– Excel æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}"})
            return {"error": f"è¯»å– Excel æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}"}
            
    except Exception as e:
        # ç¡®ä¿ä¸´æ—¶æ–‡ä»¶è¢«åˆ é™¤
        if os.path.exists(file_path):
            os.remove(file_path)
        return {"error": f"å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}"}

# ä¿®æ”¹æ ¹è·¯å¾„å¤„ç†ç¨‹åºï¼Œé‡å®šå‘åˆ°å‰ç«¯
@app.get("/", response_class=HTMLResponse)
async def root():
    return """
    <!DOCTYPE html>
    <html>
    <head>
        <title>å°çº¢ä¹¦çˆ¬è™«å·¥å…·</title>
        <meta charset="UTF-8">
        <meta http-equiv="refresh" content="0;url=/frontend/index.html">
    </head>
    <body>
        <p>æ­£åœ¨é‡å®šå‘åˆ°å°çº¢ä¹¦çˆ¬è™«å·¥å…·...</p>
    </body>
    </html>
    """

@app.get("/api/health")
async def health_check():
    return {"status": "ok", "timestamp": datetime.now().isoformat()}

@app.post("/api/update-cookie")
async def update_cookie(cookie_string: str = Form(...)):
    """æ›´æ–°cookie"""
    try:
        # è§£æcookieå­—ç¬¦ä¸²
        cookies = {}
        for item in cookie_string.split(';'):
            if '=' in item:
                key, value = item.strip().split('=', 1)
                cookies[key] = value
        
        # æ›´æ–°redbookæ¨¡å—ä¸­çš„cookies
        redbook.cookies = cookies
        
        processing_status.append({"status": "success", "message": f"Cookieå·²æ›´æ–°ï¼ŒåŒ…å« {len(cookies)} ä¸ªå­—æ®µ"})
        
        return {"message": "Cookieæ›´æ–°æˆåŠŸ", "cookie_count": len(cookies)}
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        processing_status.append({"status": "error", "message": f"Cookieæ›´æ–°å¤±è´¥: {str(e)}"})
        return {"error": f"Cookieæ›´æ–°å¤±è´¥: {str(e)}", "traceback": error_detail}

@app.get("/api/get-cookie")
async def get_current_cookie():
    """è·å–å½“å‰cookie"""
    try:
        current_cookies = redbook.cookies
        # å°†cookiesè½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼
        cookie_string = "; ".join([f"{key}={value}" for key, value in current_cookies.items()])
        return {
            "cookies": current_cookies, 
            "cookie_string": cookie_string,
            "cookie_count": len(current_cookies)
        }
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        return {"error": f"è·å–Cookieå¤±è´¥: {str(e)}", "traceback": error_detail}

@app.get("/api/download-memory")
async def download_memory():
    """é€šè¿‡å†…å­˜æµç›´æ¥ä¸‹è½½Excelï¼Œå®Œå…¨ç»•è¿‡æ–‡ä»¶ç³»ç»Ÿ"""
    global latest_scraped_data, latest_scrape_timestamp
    
    print(f"ğŸ” å†…å­˜ä¸‹è½½è°ƒè¯•ä¿¡æ¯:")
    print(f"  latest_scraped_data: {latest_scraped_data is not None}")
    print(f"  latest_scrape_timestamp: {latest_scrape_timestamp}")
    if latest_scraped_data:
        print(f"  æ•°æ®æ¡æ•°: {len(latest_scraped_data)}")
        print(f"  æ•°æ®é¢„è§ˆ: {latest_scraped_data[:2] if len(latest_scraped_data) > 0 else 'ç©º'}")
    
    if not latest_scraped_data:
        # å°è¯•ä»æ–‡ä»¶ç³»ç»Ÿæ¢å¤æ•°æ®
        print("ğŸ”„ å†…å­˜ä¸­æ²¡æœ‰æ•°æ®ï¼Œå°è¯•ä»æ–‡ä»¶ç³»ç»Ÿæ¢å¤...")
        try:
            # æŸ¥æ‰¾æœ€æ–°çš„Excelæ–‡ä»¶
            import glob
            excel_files = glob.glob("*.xlsx") + glob.glob("results/*.xlsx") + glob.glob("/tmp/*.xlsx")
            if excel_files:
                latest_file = max(excel_files, key=os.path.getctime)
                print(f"ğŸ“ æ‰¾åˆ°æ–‡ä»¶: {latest_file}")
                # è¯»å–Excelæ–‡ä»¶å¹¶è½¬æ¢ä¸ºæ•°æ®
                df = pd.read_excel(latest_file)
                latest_scraped_data = df.to_dict('records')
                print(f"âœ… ä»æ–‡ä»¶æ¢å¤æ•°æ®æˆåŠŸï¼Œæ¡æ•°: {len(latest_scraped_data)}")
            else:
                return {"error": "æ²¡æœ‰å¯ä¸‹è½½çš„æ•°æ®", "message": "è¯·å…ˆçˆ¬å–æ•°æ®"}
        except Exception as e:
            print(f"âŒ ä»æ–‡ä»¶æ¢å¤æ•°æ®å¤±è´¥: {e}")
            return {"error": "æ²¡æœ‰å¯ä¸‹è½½çš„æ•°æ®", "message": "è¯·å…ˆçˆ¬å–æ•°æ®"}
    
    try:
        # åˆ›å»ºDataFrame
        df = pd.DataFrame(latest_scraped_data)
        
        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = latest_scrape_timestamp or datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"å°çº¢ä¹¦è¾¾äººæ•°æ®_{timestamp}.xlsx"
        
        # åˆ›å»ºå†…å­˜æµ
        output = io.BytesIO()
        
        # ç›´æ¥å†™å…¥å†…å­˜æµ
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            df.to_excel(writer, index=False, sheet_name='è¾¾äººæ•°æ®')
        
        # é‡ç½®æµä½ç½®
        output.seek(0)
        
        # è¿”å›æ–‡ä»¶æµ
        return StreamingResponse(
            io.BytesIO(output.read()),
            media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            headers={"Content-Disposition": f"attachment; filename={filename}"}
        )
        
    except Exception as e:
        return {"error": f"ç”ŸæˆExcelå¤±è´¥: {str(e)}"}

@app.get("/api/download-base64")
async def download_base64():
    """è¿”å›Base64ç¼–ç çš„Excelæ•°æ®ä½œä¸ºç»ˆæå¤‡ç”¨æ–¹æ¡ˆ"""
    global latest_scraped_data, latest_scrape_timestamp
    
    if not latest_scraped_data:
        return {"error": "æ²¡æœ‰å¯ä¸‹è½½çš„æ•°æ®", "message": "è¯·å…ˆçˆ¬å–æ•°æ®"}
    
    try:
        import base64
        
        # åˆ›å»ºDataFrame
        df = pd.DataFrame(latest_scraped_data)
        
        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = latest_scrape_timestamp or datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"å°çº¢ä¹¦è¾¾äººæ•°æ®_{timestamp}.xlsx"
        
        # åˆ›å»ºå†…å­˜æµ
        output = io.BytesIO()
        
        # å†™å…¥Excel
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            df.to_excel(writer, index=False, sheet_name='è¾¾äººæ•°æ®')
        
        # è·å–äºŒè¿›åˆ¶æ•°æ®
        excel_data = output.getvalue()
        
        # ç¼–ç ä¸ºBase64
        base64_data = base64.b64encode(excel_data).decode('utf-8')
        
        return {
            "success": True,
            "filename": filename,
            "data": base64_data,
            "size": len(excel_data),
            "message": "Base64æ•°æ®ä¼ è¾“æˆåŠŸ"
        }
        
    except Exception as e:
        return {"error": f"ç”ŸæˆBase64æ•°æ®å¤±è´¥: {str(e)}"}

@app.get("/api/validate-cookie")
async def validate_cookie():
    """éªŒè¯cookieæœ‰æ•ˆæ€§å’Œè·å–ä¿¡æ¯"""
    try:
        current_cookies = redbook.cookies
        
        # åˆ†æcookieä¿¡æ¯
        cookie_info = analyze_cookie_expiry(current_cookies)
        
        # æµ‹è¯•cookieæ˜¯å¦æœ‰æ•ˆ
        validity_result = await test_cookie_validity(current_cookies)
        
        return {
            "is_valid": validity_result.get("is_valid"),
            "test_message": validity_result.get("message", ""),
            "test_results": validity_result.get("test_results", []),
            "cookie_info": cookie_info,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        return {"error": f"éªŒè¯Cookieå¤±è´¥: {str(e)}", "traceback": error_detail}

async def test_cookie_validity(cookies):
    """é€šè¿‡å®é™…APIè°ƒç”¨æµ‹è¯•cookieæ˜¯å¦æœ‰æ•ˆ"""
    try:
        # æµ‹è¯•å‡ ä¸ªä¸åŒçš„APIç«¯ç‚¹æ¥éªŒè¯cookieæœ‰æ•ˆæ€§
        test_endpoints = [
            {
                "url": "https://pgy.xiaohongshu.com/api/solar/cooperator/user/profile",
                "description": "ç”¨æˆ·é…ç½®ä¿¡æ¯"
            },
            {
                "url": "https://pgy.xiaohongshu.com/api/pgy/kol/search/bloggers",
                "description": "åšä¸»æœç´¢API"
            }
        ]
        
        headers = {
            'accept': 'application/json, text/plain, */*',
            'accept-language': 'zh-CN,zh;q=0.9',
            'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36',
            'referer': 'https://pgy.xiaohongshu.com/solar/pre-trade/home',
        }
        
        test_results = []
        
        for endpoint in test_endpoints:
            try:
                response = requests.get(endpoint["url"], headers=headers, cookies=cookies, timeout=10)
                
                result = {
                    "endpoint": endpoint["description"],
                    "status_code": response.status_code,
                    "success": response.status_code == 200,
                    "unauthorized": response.status_code in [401, 403]
                }
                
                test_results.append(result)
                
                # å¦‚æœä»»ä½•ä¸€ä¸ªç«¯ç‚¹è¿”å›401/403ï¼Œè¯´æ˜cookieå¯èƒ½æ— æ•ˆ
                if response.status_code in [401, 403]:
                    return {
                        "is_valid": False,
                        "test_results": test_results,
                        "message": f"APIæµ‹è¯•å¤±è´¥ï¼š{endpoint['description']} è¿”å› {response.status_code}"
                    }
                    
            except Exception as e:
                test_results.append({
                    "endpoint": endpoint["description"],
                    "error": str(e),
                    "success": False
                })
        
        # å¦‚æœæ‰€æœ‰æµ‹è¯•éƒ½é€šè¿‡ï¼Œè¯´æ˜cookieå¯èƒ½æœ‰æ•ˆ
        successful_tests = sum(1 for r in test_results if r.get("success", False))
        
        return {
            "is_valid": successful_tests > 0,
            "test_results": test_results,
            "message": f"å®Œæˆ {len(test_results)} é¡¹æµ‹è¯•ï¼Œ{successful_tests} é¡¹æˆåŠŸ"
        }
        
    except Exception as e:
        return {
            "is_valid": None,
            "error": str(e),
            "message": "ç½‘ç»œæµ‹è¯•å¤±è´¥ï¼Œæ— æ³•ç¡®å®šcookieçŠ¶æ€"
        }

def analyze_cookie_expiry(cookies):
    """åˆ†æcookieä¿¡æ¯ï¼ˆä¸çŒœæµ‹è¿‡æœŸæ—¶é—´ï¼‰"""
    import time
    from datetime import datetime, timedelta
    
    cookie_info = {
        "loadts": None,
        "loadts_readable": None,
        "session_tokens": [],
        "important_note": "âš ï¸ æˆ‘ä»¬æ— æ³•ä»cookieä¸­å‡†ç¡®è·å–è¿‡æœŸæ—¶é—´ï¼Œåªèƒ½é€šè¿‡å®é™…APIæµ‹è¯•æ¥éªŒè¯æœ‰æ•ˆæ€§"
    }
    
    # è§£æloadtsæ—¶é—´æˆ³ï¼ˆä½†æ˜ç¡®è¿™ä¸æ˜¯è¿‡æœŸæ—¶é—´ï¼‰
    if "loadts" in cookies:
        try:
            loadts = cookies["loadts"]
            
            # å°è¯•ä¸åŒçš„æ—¶é—´æˆ³æ ¼å¼
            if len(loadts) <= 10:
                # ç§’çº§æ—¶é—´æˆ³
                loadts_datetime = datetime.fromtimestamp(int(loadts))
            else:
                # æ¯«ç§’çº§æ—¶é—´æˆ³ï¼Œå¯èƒ½éœ€è¦è¡¥0
                if len(loadts) == 11:
                    loadts_ms = int(loadts + '00')
                elif len(loadts) == 12:
                    loadts_ms = int(loadts + '0')
                else:
                    loadts_ms = int(loadts)
                loadts_datetime = datetime.fromtimestamp(loadts_ms / 1000)
            
            cookie_info["loadts"] = loadts
            cookie_info["loadts_readable"] = loadts_datetime.strftime("%Y-%m-%d %H:%M:%S")
            cookie_info["loadts_note"] = "è¿™å¯èƒ½æ˜¯ä¼šè¯åˆ›å»ºæ—¶é—´ï¼Œä¸æ˜¯è¿‡æœŸæ—¶é—´"
            
        except (ValueError, TypeError) as e:
            cookie_info["loadts_readable"] = f"æ— æ³•è§£ææ—¶é—´æˆ³: {e}"
    
    # è¯†åˆ«é‡è¦çš„ä¼šè¯ä»¤ç‰Œ
    session_keys = ["web_session", "customer-sso-sid", "solar.beaker.session.id", 
                   "access-token-pgy.xiaohongshu.com", "access-token-pgy.beta.xiaohongshu.com"]
    
    for key in session_keys:
        if key in cookies:
            cookie_info["session_tokens"].append({
                "key": key,
                "length": len(cookies[key]),
                "prefix": cookies[key][:15] + "..." if len(cookies[key]) > 15 else cookies[key]
            })
    
    # æ·»åŠ è·å–çœŸå®è¿‡æœŸæ—¶é—´çš„è¯´æ˜
    cookie_info["how_to_get_real_expiry"] = [
        "ğŸ” çœŸå®è¿‡æœŸæ—¶é—´åªèƒ½é€šè¿‡ä»¥ä¸‹æ–¹å¼è·å–ï¼š",
        "1. æµè§ˆå™¨å¼€å‘è€…å·¥å…· â†’ Application â†’ Cookies â†’ æŸ¥çœ‹ Expires åˆ—",
        "2. Network é¢æ¿ â†’ æŸ¥çœ‹ Set-Cookie å“åº”å¤´",
        "3. æœ€å¯é çš„æ–¹æ³•ï¼šå®šæœŸæµ‹è¯•APIè°ƒç”¨æ˜¯å¦è¿˜æœ‰æ•ˆ"
    ]
    
    return cookie_info

# è‡ªåŠ¨ ping æœåŠ¡ï¼Œé˜²æ­¢ Heroku ä¼‘çœ 
def ping_service():
    app_url = os.environ.get('APP_URL')
    if not app_url:
        print("WARNING: APP_URL ç¯å¢ƒå˜é‡æœªè®¾ç½®ï¼Œè‡ªåŠ¨ ping åŠŸèƒ½ä¸ä¼šå·¥ä½œ")
        return
    
    while True:
        try:
            response = requests.get(f"{app_url}/api/health")
            print(f"è‡ªåŠ¨ ping æœåŠ¡: {response.status_code}")
        except Exception as e:
            print(f"è‡ªåŠ¨ ping å¤±è´¥: {e}")
        
        # æ¯ 25 åˆ†é’Ÿ ping ä¸€æ¬¡ï¼Œä½äº Heroku çš„ 30 åˆ†é’Ÿä¼‘çœ é˜ˆå€¼
        time.sleep(25 * 60)

# åœ¨ä¸»å‡½æ•°ä¸­å¯åŠ¨ ping çº¿ç¨‹
if __name__ == "__main__":
    # å¯åŠ¨è‡ªåŠ¨ ping çº¿ç¨‹
    if os.environ.get('PREVENT_SLEEP') == 'true':
        ping_thread = threading.Thread(target=ping_service, daemon=True)
        ping_thread.start()
    
    import uvicorn
    port = int(os.environ.get('PORT', 8008))
    uvicorn.run("api:app", host="0.0.0.0", port=port, log_level="info") 